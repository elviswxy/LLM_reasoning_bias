{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b765cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa074f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for context-based heatmaps\n",
    "def load_bias_heatmap_by_condition(file_path, num_points=100):\n",
    "    ambig_rows = []\n",
    "    disambig_rows = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            steps = entry.get(\"gpt_4o_judge\", [])\n",
    "            bias_scores = [s[\"bias_score\"] for s in steps if \"bias_score\" in s]\n",
    "            condition = entry.get(\"context_condition\", None)\n",
    "            if len(bias_scores) < 2 or condition not in (\"ambig\", \"disambig\"):\n",
    "                continue\n",
    "            original_x = np.linspace(0, 1, len(bias_scores))\n",
    "            target_x = np.linspace(0, 1, num_points)\n",
    "            interp_fn = interp1d(original_x, bias_scores, kind='nearest', fill_value='extrapolate')\n",
    "            normalized_bias = interp_fn(target_x)\n",
    "            if condition == \"ambig\":\n",
    "                ambig_rows.append(normalized_bias)\n",
    "            elif condition == \"disambig\":\n",
    "                disambig_rows.append(normalized_bias)\n",
    "    return np.array(ambig_rows), np.array(disambig_rows)\n",
    "\n",
    "# Helper function for standard heatmaps\n",
    "def load_bias_heatmap_data(file_path, num_points=100):\n",
    "    heatmap_rows = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            steps = entry.get(\"gpt_4o_judge\", [])\n",
    "            bias_scores = [s[\"bias_score\"] for s in steps if \"bias_score\" in s]\n",
    "            if len(bias_scores) < 2:\n",
    "                continue\n",
    "            original_x = np.linspace(0, 1, len(bias_scores))\n",
    "            target_x = np.linspace(0, 1, num_points)\n",
    "            interp_fn = interp1d(original_x, bias_scores, kind='nearest', fill_value='extrapolate')\n",
    "            normalized_bias = interp_fn(target_x)\n",
    "            heatmap_rows.append(normalized_bias)\n",
    "    return np.array(heatmap_rows)\n",
    "\n",
    "# File paths\n",
    "file_8b_correct = \"/Users/jimmynian/code/step_fairness_eval/llm_as_judge_results/Age_llama3_8b_deepseek_8b_equal_equal_gpt4o_majority_voting.jsonl\"\n",
    "file_8b_wrong = \"/Users/jimmynian/code/step_fairness_eval/llm_as_judge_results/Age_llama3_8b_deepseek_8b_equal_not_equal_gpt4o_majority_voting.jsonl\"\n",
    "file_32b_correct = \"/Users/jimmynian/code/step_fairness_eval/llm_as_judge_results/Age_qwen_25_deepseek_32b_equal_equal_gpt4o_majority_voting.jsonl\"\n",
    "file_32b_wrong = \"/Users/jimmynian/code/step_fairness_eval/llm_as_judge_results/Age_qwen_25_deepseek_32b_equal_not_equal_gpt4o_majority_voting.jsonl\"\n",
    "save_dir = \"./imgs\"\n",
    "\n",
    "# Load data for 8B/32B correct/wrong\n",
    "correct_8b = load_bias_heatmap_data(file_8b_correct)\n",
    "wrong_8b = load_bias_heatmap_data(file_8b_wrong)\n",
    "correct_32b = load_bias_heatmap_data(file_32b_correct)\n",
    "wrong_32b = load_bias_heatmap_data(file_32b_wrong)\n",
    "\n",
    "# Load context-specific data for 8B wrong\n",
    "ambig_wrong, disambig_wrong = load_bias_heatmap_by_condition(file_8b_wrong)\n",
    "\n",
    "# Colormap and normalization\n",
    "colors = [\n",
    "    \"#ffffff\",  # Bias 0\n",
    "    \"#ffb3b3\",  # Bias 1\n",
    "    \"#ff6666\",  # Bias 2\n",
    "    \"#cc0000\",  # Bias 3\n",
    "    \"#660000\"   # Bias 4\n",
    "]\n",
    "cmap = mcolors.ListedColormap(colors)\n",
    "bounds = [0, 1, 2, 3, 4, 5]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "cbar_ticks = [0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "cbar_labels = [\"Bias 0\", \"Bias 1\", \"Bias 2\", \"Bias 3\", \"Bias 4\"]\n",
    "\n",
    "def plot_heatmap(\n",
    "    data, title, title_fontsize=24, title_fontweight='bold', figsize=(8, 4),\n",
    "    axis_labelsize=20, cbar_labelsize=20, cbar_ticksize=12, save_path=None\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(data, aspect='auto', cmap=cmap, norm=norm)\n",
    "    ax.set_title(title, fontsize=title_fontsize, fontweight=title_fontweight, pad=20)\n",
    "    ax.set_xlabel(\"Normalized Reasoning Step\", fontsize=axis_labelsize)\n",
    "    ax.set_ylabel(\"Question Index\", fontsize=axis_labelsize)\n",
    "    cbar = fig.colorbar(im, ax=ax, ticks=cbar_ticks, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(cbar_labels, fontsize=cbar_ticksize)\n",
    "    cbar.ax.tick_params(labelsize=cbar_ticksize)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        fig.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 1. Deepseek 8B Correct Answers\n",
    "plot_heatmap(\n",
    "    correct_8b,\n",
    "    \"\",\n",
    "    save_path=os.path.join(save_dir, \"8b_equal_equal.pdf\")\n",
    ")\n",
    "\n",
    "# 2. Deepseek 8B Incorrect Answers\n",
    "plot_heatmap(\n",
    "    wrong_8b,\n",
    "    \"\",\n",
    "    save_path=os.path.join(save_dir, \"8b_equal_not_equal.pdf\")\n",
    ")\n",
    "\n",
    "# 3. Deepseek 32B Correct Answers\n",
    "plot_heatmap(\n",
    "    correct_32b,\n",
    "    \"\",\n",
    "    save_path=os.path.join(save_dir, \"32b_equal_equal.pdf\")\n",
    ")\n",
    "\n",
    "# 4. Deepseek 32B Incorrect Answers\n",
    "plot_heatmap(\n",
    "    wrong_32b,\n",
    "    \"\",\n",
    "    save_path=os.path.join(save_dir, \"32b_equal_not_equal.pdf\")\n",
    ")\n",
    "\n",
    "plot_heatmap(\n",
    "    ambig_wrong,\n",
    "    \"\",  # Empty title\n",
    "    figsize=(8, 4),  # Reduced height\n",
    "    save_path=os.path.join(save_dir, \"8b_ene_ambig.pdf\")\n",
    ")\n",
    "\n",
    "# 6. Deepseek 8B Wrong Disambiguated Context\n",
    "plot_heatmap(\n",
    "    disambig_wrong,\n",
    "    \"\",  # Empty title\n",
    "    figsize=(8, 4),  # Reduced height\n",
    "    save_path=os.path.join(save_dir, \"8b_ene_disambig.pdf\")\n",
    ")\n",
    "\n",
    "def compute_average_bias(data, name):\n",
    "    # data shape: (num_questions, num_points)\n",
    "    per_row_avg = data.mean(axis=1)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Number of examples: {len(per_row_avg)}\")\n",
    "    print(f\"  Mean of averages: {per_row_avg.mean():.3f}\")\n",
    "    print(f\"  Std of averages: {per_row_avg.std():.3f}\")\n",
    "    return per_row_avg\n",
    "\n",
    "# Compute and print averages\n",
    "avg_correct_8b = compute_average_bias(correct_8b, \"8B Correct\")\n",
    "avg_wrong_8b = compute_average_bias(wrong_8b, \"8B Wrong\")\n",
    "avg_correct_32b = compute_average_bias(correct_32b, \"32B Correct\")\n",
    "avg_wrong_32b = compute_average_bias(wrong_32b, \"32B Wrong\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defuse39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
